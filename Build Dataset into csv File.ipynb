{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Build New Dataset\n",
    "\n",
    "### TODO TASKS\n",
    "*[7.20] Meeting with my supervisor to discuss the dataset so far and the next steps to be taken*\n",
    "- Clean the data for duplicates and empty lines\n",
    "- Reorganize keywords with one-hot encoding for specific subject (hate crime, discrimination, coronavirus, etc)\n",
    "- Drop unnecessary column, filter date range to start with the same date on NYT Covid dataset\n",
    "- Explore the dataset with the news-desk count\n",
    "- Aggregate by date with the sum of the specific subject, article count before merging\n",
    "- Download NYT Covid dataset with dates\n",
    "- Finalize merged dataset with the date\n",
    "- Distribution curve and general exploratory tasks\n",
    "\n",
    "#### Tags to be considered\n",
    "- 'subject', 'Assaults'\n",
    "- 'subject', 'Minorities'\n",
    "- 'subject', 'Workplace Hazards and Violations'\n",
    "- 'subject', 'Coronavirus (2019-nCoV)'\n",
    "- 'subject', 'Mass Shootings'\n",
    "- 'subject', 'Quarantine (Life and Culture)'\n",
    "- 'subject', 'Discrimination'\n",
    "- 'subject', 'Demonstrations, Protests and Riots'\n",
    "- 'subject', 'Murders, Attempted Murders and Homicides'\n",
    "- 'subject', 'Race and Ethnicity'\n",
    "- 'subject', 'Atlanta Spa Shootings (2021)'\n",
    "- 'subject', 'Hate Crimes'\n",
    "- 'subject', 'Apologies'\n",
    "\n",
    "\n",
    "#### Set up the key and use a configparser to hide the key details"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set up the key\n",
    "import os\n",
    "import configparser\n",
    "# Use a parser for the configuration file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "configs = configparser.ConfigParser()\n",
    "# Get the current directory to the main file README.md\n",
    "currentDir = os.path.dirname(\"README.md\")\n",
    "# Get the path file to the config file\n",
    "configDir = os.path.join(currentDir, \"config/settings.cfg\")\n",
    "configs.read(configDir)\n",
    "# Get the key\n",
    "apiKey = configs.get(\"nytimes\", \"api_key\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find total numbers of articles in the topic with the numbers of hits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "subject = \"subject:Asian-Americans\"\n",
    "query = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq={subject}&sort=newest&api-key={apiKey}'\n",
    "response = requests.get(query).json()\n",
    "numHits = response['response']['meta']['hits']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Method to set up and parse the\n",
    "import time\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "day = datetime(2020, 1, 21).date()\n",
    "numPerPages = 10\n",
    "def isNotValid(article) -> bool:\n",
    "    \"\"\"\n",
    "    Method to check if the article has a valid headline\n",
    "\n",
    "    :param article: The information of the article\n",
    "    :return: True if not valid, False if valid\n",
    "    \"\"\"\n",
    "    if type(article['headline']) == dict and 'main' in article['headline'] and article['headline']['main'] is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def getDataSorted() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main method to send request and parse response with the subject\n",
    "\n",
    "    :return: Dataset with all the articles parsed as panda dataframe\n",
    "    \"\"\"\n",
    "    # Result dataset\n",
    "    dataset = {'headline': [],\n",
    "        'date': [],\n",
    "        'news_desk': [],\n",
    "        'word_count': [],\n",
    "        'Hate Crimes': [],\n",
    "        'Discrimination': [],\n",
    "        'Race and Ethnicity': [],\n",
    "        'Atlanta Spa Shootings (2021)': [],\n",
    "        'Murders, Attempted Murders and Homicides': [],\n",
    "        'Demonstrations, Protests and Riots': [],\n",
    "        'Mass Shootings': [],\n",
    "        'Quarantine (Life and Culture)': [],\n",
    "        'Assaults': [],\n",
    "        'Minorities': [],\n",
    "        'Workplace Hazards and Violations': [],\n",
    "        'Coronavirus (2019-nCoV)': [],\n",
    "        'url': []}\n",
    "\n",
    "    breakCondition = False\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    # Count number of articles\n",
    "    total = 0\n",
    "    # Loop through the page\n",
    "    for page in range(numHits // numPerPages + 1):\n",
    "        # Send request to the page gradually\n",
    "        q = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq={subject}&page={page}&sort=newest&api-key={apiKey}'\n",
    "        r = requests.get(q).json()\n",
    "        # Based on preliminary parsing, get the list of article from the file\n",
    "        articleList = r['response']['docs']\n",
    "        # Return dataframe\n",
    "        frame = getRequestUpdate(articleList, breakCondition)\n",
    "        # Return\n",
    "        if len(frame) == 0:\n",
    "            break\n",
    "        # Add to dataset\n",
    "        dataset = dataset.append(frame, ignore_index=True)\n",
    "        # Count pages\n",
    "        total += len(frame)\n",
    "        # Sleep before new request\n",
    "        time.sleep(6)\n",
    "        # Print message to know finish with the page\n",
    "        print(\"Finish with page\", page)\n",
    "    # Print when done with the numbers of total articles\n",
    "    print(f'Finished with all pages, total of {str(total)}')\n",
    "    # Create csv file\n",
    "    csv_path = \"Updated Asians American NYT Dataset.csv\"\n",
    "    dataset.to_csv(csv_path, index=False)\n",
    "    return dataset\n",
    "\n",
    "tags = {'Hate Crimes',\n",
    "        'Discrimination',\n",
    "        'Race and Ethnicity',\n",
    "        'Atlanta Spa Shootings (2021)',\n",
    "        'Murders, Attempted Murders and Homicides',\n",
    "        'Demonstrations, Protests and Riots',\n",
    "        'Mass Shootings',\n",
    "        'Quarantine (Life and Culture)',\n",
    "        'Assaults',\n",
    "        'Minorities',\n",
    "        'Workplace Hazards and Violations',\n",
    "        'Coronavirus (2019-nCoV)'}\n",
    "\n",
    "def keywordCheck(frame, keywords, num):\n",
    "    \"\"\"\n",
    "    Method to do one-hot encoding for the keywords\n",
    "\n",
    "    :param num: The article number on the list\n",
    "    :param frame: the current dataframe\n",
    "    :param keywords: the list of keywords\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for keyword in keywords:\n",
    "        if keyword['name'] != 'subject':\n",
    "            continue\n",
    "        # All the keywords are subject\n",
    "        if keyword['value'] == 'Assaults':\n",
    "            frame['Assaults'].append(1)\n",
    "        # minorities\n",
    "        elif keyword['value'] == 'Minorities':\n",
    "            frame['Minorities'].append(1)\n",
    "        # hazards\n",
    "        elif keyword['value'] == 'Workplace Hazards and Violations':\n",
    "            frame['Workplace Hazards and Violations'].append(1)\n",
    "        # covid 19\n",
    "        elif keyword['value'] == 'Coronavirus (2019-nCoV)':\n",
    "            frame['Coronavirus (2019-nCoV)'].append(1)\n",
    "        # shootings\n",
    "        elif keyword['value'] =='Mass Shootings' :\n",
    "            frame['Mass Shootings'].append(1)\n",
    "        # quarantine\n",
    "        elif keyword['value'] == 'Quarantine (Life and Culture)' :\n",
    "            frame['Quarantine (Life and Culture)'].append(1)\n",
    "        # Discrimination\n",
    "        elif keyword['value'] == 'Discrimination':\n",
    "            frame['Discrimination'].append(1)\n",
    "        # Protest and riot\n",
    "        elif keyword['value'] == 'Demonstrations, Protests and Riots':\n",
    "            frame['Demonstrations, Protests and Riots'].append(1)\n",
    "        # Murders, homicides\n",
    "        elif keyword['value'] == 'Murders, Attempted Murders and Homicides':\n",
    "            frame['Murders, Attempted Murders and Homicides'].append(1)\n",
    "        # Race and ethnicity\n",
    "        elif keyword['value'] == 'Race and Ethnicity':\n",
    "            frame['Race and Ethnicity'].append(1)\n",
    "        # Atlanta\n",
    "        elif keyword['value'] == 'Atlanta Spa Shootings (2021)':\n",
    "            frame['Atlanta Spa Shootings (2021)'].append(1)\n",
    "        # Discrimination\n",
    "        elif keyword['value'] == 'Hate Crimes':\n",
    "            frame['Hate Crimes'].append(1)\n",
    "\n",
    "    for tag in tags:\n",
    "        # print(frame[tag])\n",
    "        while len(frame[tag]) < num + 1:\n",
    "            frame[tag].append(0)\n",
    "\n",
    "\n",
    "def getRequestUpdate(articleList, breakCondition) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Method to parse article and return as a data frame\n",
    "\n",
    "    :param breakCondition:\n",
    "    :param articleList: list of article from response['response']['docs']\n",
    "    :return: dataframe of the article after parsing\n",
    "    \"\"\"\n",
    "    frame = {'headline': [],\n",
    "        'date': [],\n",
    "        'news_desk': [],\n",
    "        'word_count': [],\n",
    "        'Hate Crimes': [],\n",
    "        'Discrimination': [],\n",
    "        'Race and Ethnicity': [],\n",
    "        'Atlanta Spa Shootings (2021)': [],\n",
    "        'Murders, Attempted Murders and Homicides': [],\n",
    "        'Demonstrations, Protests and Riots': [],\n",
    "        'Mass Shootings': [],\n",
    "        'Quarantine (Life and Culture)': [],\n",
    "        'Assaults': [],\n",
    "        'Minorities': [],\n",
    "        'Workplace Hazards and Violations': [],\n",
    "        'Coronavirus (2019-nCoV)': [],\n",
    "        'url': []}\n",
    "    for idx, article in enumerate(articleList):\n",
    "        # Check if article is valid\n",
    "        if isNotValid(article):\n",
    "            continue\n",
    "        # Date parse\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        # Return when the date is larger\n",
    "        if date < day:\n",
    "            break\n",
    "        frame['date'].append(str(date))\n",
    "        # Headline parse\n",
    "        frame['headline'].append(article['headline']['main'])\n",
    "        # Link URL parse\n",
    "        frame['url'].append(article['web_url'])\n",
    "\n",
    "        # News Desk parse\n",
    "        if 'news_desk' in article:\n",
    "            frame['news_desk'].append(article['news_desk'])\n",
    "        else:\n",
    "            frame['news_desk'].append(article[None])\n",
    "        # Word count parse\n",
    "        if 'word_count' in article:\n",
    "            frame['word_count'].append(article['word_count'])\n",
    "        else:\n",
    "            frame['word_count'].append(article[None])\n",
    "\n",
    "        keywordCheck(frame, article['keywords'], idx)\n",
    "\n",
    "    return pd.DataFrame(frame)\n",
    "\n",
    "updatedData = getDataSorted()\n",
    "updatedData.head(10)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}