{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build The Dataset\n",
    "\n",
    "\n",
    "*Exploratory work to familiarize myself with New York Times API requests and dataset format*\n",
    "\n",
    "#### Set up the key and usin a configparser to hide the key details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Set up the key\n",
    "import os\n",
    "import configparser\n",
    "# Use a parser for the configuration file\n",
    "import pandas as pd\n",
    "\n",
    "configs = configparser.ConfigParser()\n",
    "# Get the current directory to the main file README.md\n",
    "currentDir = os.path.dirname(\"README.md\")\n",
    "# Get the path file to the config file\n",
    "configDir = os.path.join(currentDir, \"config/settings.cfg\")\n",
    "configs.read(configDir)\n",
    "# Get the key\n",
    "apiKey = configs.get(\"nytimes\", \"api_key\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Find total numbers of articles in the topic with the numbers of hits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "import requests\n",
    "subject = \"subject:Asian-Americans\"\n",
    "query = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq={subject}&sort=newest&api-key={apiKey}'\n",
    "response = requests.get(query).json()\n",
    "numHits = response['response']['meta']['hits']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Structure the query and parse the file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Method to set up and parse the\n",
    "numPerPages = 10\n",
    "import time\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def getData() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main method to send request and parse response with the subject\n",
    "\n",
    "    :return: Dataset with all the articles parsed as panda dataframe\n",
    "    \"\"\"\n",
    "    # Result dataset\n",
    "    dataset = {'headline': [],\n",
    "        'date': [],\n",
    "        'doc_type': [],\n",
    "        'author': [],\n",
    "        'section': [],\n",
    "        'url': [],\n",
    "        'news_desk': [],\n",
    "        'material_type': [],\n",
    "        'word_count': [],\n",
    "        'keywords': []}\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    # Count number of articles\n",
    "    total = 0\n",
    "\n",
    "    # Loop through the page\n",
    "    for page in range(numHits // numPerPages + 1):\n",
    "        # Send request to the page gradually\n",
    "        q = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq={subject}&page={page}&sort=newest&api-key={apiKey}'\n",
    "        r = requests.get(q).json()\n",
    "        # Based on preliminary parsing, get the list of article from the file\n",
    "        articleList = r['response']['docs']\n",
    "        # Return dataframe\n",
    "        frame = getRequest(articleList)\n",
    "        # Add to dataset\n",
    "        dataset = dataset.append(frame, ignore_index=True)\n",
    "        # Count pages\n",
    "        total += len(frame)\n",
    "        # Sleep before new request\n",
    "        time.sleep(6)\n",
    "        # Print message to know finish with the page\n",
    "        print(\"Finish with page\", page)\n",
    "\n",
    "    # Print when done with the numbers of total articles\n",
    "    print(f'Finished with all pages, total of {str(total)}')\n",
    "    # Create csv file\n",
    "    csv_path = \"Asians American NYT Dataset.csv\"\n",
    "    dataset.to_csv(csv_path, index=False)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def isNotValid(article) -> bool:\n",
    "    \"\"\"\n",
    "    Method to check if the article has a valid headline\n",
    "\n",
    "    :param article: The information of the article\n",
    "    :return: True if not valid, False if valid\n",
    "    \"\"\"\n",
    "    if type(article['headline']) == dict and 'main' in article['headline'] and article['headline']['main'] is not None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def getRequest(articleList) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Method to parse article and return as a data frame\n",
    "\n",
    "    :param articleList: list of article from response['response']['docs']\n",
    "    :return: dataframe of the article after parsing\n",
    "    \"\"\"\n",
    "    frame = {'headline': [],\n",
    "        'date': [],\n",
    "        'doc_type': [],\n",
    "        'author': [],\n",
    "        'section': [],\n",
    "        'url': [],\n",
    "        'news_desk': [],\n",
    "        'material_type': [],\n",
    "        'word_count': [],\n",
    "        'keywords': []}\n",
    "    for article in articleList:\n",
    "        # Check if article is valid\n",
    "        if isNotValid(article):\n",
    "            continue\n",
    "        # Date parse\n",
    "        date = dateutil.parser.parse(article['pub_date']).date()\n",
    "        frame['date'].append(date)\n",
    "        # Headline parse\n",
    "        frame['headline'].append(article['headline']['main'])\n",
    "        # Document type parse\n",
    "        frame['doc_type'].append(article['document_type'])\n",
    "        # Author parse\n",
    "        if 'person' in article['byline']:\n",
    "            person = article['byline']['person']\n",
    "            names = [name['firstname'] + \" \" + name['lastname'] for name in person if name['firstname'] and name['lastname']]\n",
    "            frame['author'].append(names)\n",
    "        else:\n",
    "            frame['author'].append(None)\n",
    "        # Section parse\n",
    "        if 'section' in article:\n",
    "            frame['section'].append(article['section_name'])\n",
    "        else:\n",
    "            frame['section'].append(None)\n",
    "        # Link URL parse\n",
    "        if 'web_url' in article:\n",
    "            frame['url'].append(article['web_url'])\n",
    "        else:\n",
    "            frame['url'].append(None)\n",
    "        # News Desk parse\n",
    "        if 'news_desk' in article:\n",
    "            frame['news_desk'].append(article['news_desk'])\n",
    "        else:\n",
    "            frame['news_desk'].append(article[None])\n",
    "        # Material parse:\n",
    "        if 'type_of_material' in article:\n",
    "            frame['material_type'].append(article['type_of_material'])\n",
    "        else:\n",
    "            frame['material_type'].append(None)\n",
    "        # Word count parse\n",
    "        if 'word_count' in article:\n",
    "            frame['word_count'].append(article['word_count'])\n",
    "        else:\n",
    "            frame['word_count'].append(article[None])\n",
    "        # Keyword parse\n",
    "        keywords = [(keyword['name'], keyword['value']) for keyword in article['keywords']]\n",
    "        frame['keywords'].append(keywords)\n",
    "\n",
    "    return pd.DataFrame(frame)\n",
    "\n",
    "def getFinalPage(dataset):\n",
    "    # Send request to the page gradually\n",
    "    q = f'https://api.nytimes.com/svc/search/v2/articlesearch.json?fq={subject}&page=161&api-key={apiKey}'\n",
    "    r = requests.get(q).json()\n",
    "    # Based on preliminary parsing, get the list of article from the file\n",
    "    articleList = r['response']['docs']\n",
    "    # Return dataframe\n",
    "    frame = getRequest(articleList)\n",
    "    # Add to dataset\n",
    "    dataset = dataset.append(frame, ignore_index=True)\n",
    "    # Create csv file\n",
    "    csv_path = \"Asians American NYT Dataset.csv\"\n",
    "    dataset.to_csv(csv_path, index=False)\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### TODO TASKS\n",
    "*[7.20] Meeting with my supervisor to discuss the dataset so far and the next steps to be taken*\n",
    "- Clean the data for duplicates and empty lines\n",
    "- Reorganize keywords with one-hot encoding for specific subject (hate crime, discrimination, coronavirus, etc)\n",
    "- Drop unnecessary column, filter date range to start with the same date on NYT Covid dataset\n",
    "- Explore the dataset with the news-desk count\n",
    "- Aggregate by date with the sum of the specific subject, article count before merging\n",
    "- Download NYT Covid dataset with dates\n",
    "- Finalize merged dataset with the date\n",
    "- Distribution curve and general exploratory tasks\n",
    "\n",
    "#### Tags to be considered\n",
    "- 'subject', 'Assaults'\n",
    "- 'subject', 'Minorities'\n",
    "- 'subject', 'Workplace Hazards and Violations'\n",
    "- 'subject', 'Coronavirus (2019-nCoV)'\n",
    "- 'subject', 'Mass Shootings'\n",
    "- 'subject', 'Quarantine (Life and Culture)'\n",
    "- 'subject', 'Discrimination'\n",
    "- 'subject', 'Demonstrations, Protests and Riots'\n",
    "- 'subject', 'Murders, Attempted Murders and Homicides'\n",
    "- 'subject', 'Race and Ethnicity'\n",
    "- 'subject', 'Atlanta Spa Shootings (2021)'\n",
    "- 'subject', 'Hate Crimes'\n",
    "- 'subject', 'Apologies'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}